<!DOCTYPE html>
<html><head>
        <meta http-equiv="Content-type" content="text/html; charset=UTF-8"><link rel="stylesheet" href="Spark%20shell%20-%20Environment_files/bootstrap.css" type="text/css"><link rel="stylesheet" href="Spark%20shell%20-%20Environment_files/vis-timeline-graph2d.css" type="text/css"><link rel="stylesheet" href="Spark%20shell%20-%20Environment_files/webui.css" type="text/css"><link rel="stylesheet" href="Spark%20shell%20-%20Environment_files/timeline-view.css" type="text/css"><script src="Spark%20shell%20-%20Environment_files/sorttable.js"></script><script src="Spark%20shell%20-%20Environment_files/jquery-3.js"></script><script src="Spark%20shell%20-%20Environment_files/vis-timeline-graph2d.js"></script><script src="Spark%20shell%20-%20Environment_files/bootstrap-tooltip.js"></script><script src="Spark%20shell%20-%20Environment_files/initialize-tooltips.js"></script><script src="Spark%20shell%20-%20Environment_files/table.js"></script><script src="Spark%20shell%20-%20Environment_files/timeline-view.js"></script><script src="Spark%20shell%20-%20Environment_files/log-view.js"></script><script src="Spark%20shell%20-%20Environment_files/webui.js"></script><script>setUIRoot('')</script>
        <script>setAppBasePath('')</script>
        
        
        <link rel="shortcut icon" href="Spark%20shell%20-%20Environment_files/spark-logo-77x50px-hd.png">
        <title>Spark shell - Environment</title>
      </head>
      <body>
        <div class="navbar navbar-static-top">
          <div class="navbar-inner">
            <div class="brand">
              <a href="http://localhost:4040/" class="brand">
                <img src="Spark%20shell%20-%20Environment_files/spark-logo-77x50px-hd.png">
                <span class="version">3.0.1</span>
              </a>
            </div>
            <p class="navbar-text pull-right">
              <strong title="Spark shell">Spark shell</strong> application UI
            </p>
            <ul class="nav"><li class="">
        <a href="http://localhost:4040/jobs/">Jobs</a>
      </li><li class="">
        <a href="http://localhost:4040/stages/">Stages</a>
      </li><li class="">
        <a href="http://localhost:4040/storage/">Storage</a>
      </li><li class="active">
        <a href="http://localhost:4040/environment/">Environment</a>
      </li><li class="">
        <a href="http://localhost:4040/executors/">Executors</a>
      </li><li class="">
        <a href="http://localhost:4040/SQL/">SQL</a>
      </li></ul>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row-fluid">
            <div class="span12">
              <h3 style="vertical-align: bottom; display: inline-block;">
                Environment
                
              </h3>
            </div>
          </div>
          <span>
        <span class="collapse-aggregated-runtimeInformation collapse-table" onclick="collapseTable('collapse-aggregated-runtimeInformation',
            'aggregated-runtimeInformation')">
          <h4>
            <span class="collapse-table-arrow arrow-open"></span>
            <a>Runtime Information</a>
          </h4>
        </span>
        <div class="aggregated-runtimeInformation collapsible-table">
          <table class="table table-bordered table-condensed table-striped sortable">
      <thead><tr><th class="sorttable_alpha" width="50.0%">Name</th><th class="sorttable_alpha" width="50.0%">Value</th></tr></thead>
      <tbody>
        <tr><td>Java Home</td><td>/usr/local/openjdk-8/jre</td></tr><tr><td>Java Version</td><td>1.8.0_212 (Oracle Corporation)</td></tr><tr><td>Scala Version</td><td>version 2.12.10</td></tr>
      </tbody>
    <tfoot></tfoot></table>
        </div>
        <span class="collapse-aggregated-sparkProperties collapse-table" onclick="collapseTable('collapse-aggregated-sparkProperties',
            'aggregated-sparkProperties')">
          <h4>
            <span class="collapse-table-arrow arrow-open"></span>
            <a>Spark Properties</a>
          </h4>
        </span>
        <div class="aggregated-sparkProperties collapsible-table">
          <table class="table table-bordered table-condensed table-striped sortable">
      <thead><tr><th class="sorttable_alpha" width="50.0%">Name</th><th class="sorttable_alpha" width="50.0%">Value</th></tr></thead>
      <tbody>
        <tr><td>spark.app.id</td><td>local-1613647193393</td></tr><tr><td>spark.app.name</td><td>Spark shell</td></tr><tr><td>spark.driver.host</td><td>704a9920dffd</td></tr><tr><td>spark.driver.port</td><td>39379</td></tr><tr><td>spark.executor.id</td><td>driver</td></tr><tr><td>spark.home</td><td>/spark</td></tr><tr><td>spark.jars</td><td></td></tr><tr><td>spark.master</td><td>local[*]</td></tr><tr><td>spark.repl.class.outputDir</td><td>/tmp/spark-affa6d40-a02f-4282-ba71-ff588dc370f7/repl-e71fbf23-a44f-4ee1-a637-3e0f6dcbac8b</td></tr><tr><td>spark.repl.class.uri</td><td>spark://704a9920dffd:39379/classes</td></tr><tr><td>spark.scheduler.mode</td><td>FIFO</td></tr><tr><td>spark.sql.catalogImplementation</td><td>hive</td></tr><tr><td>spark.submit.deployMode</td><td>client</td></tr><tr><td>spark.submit.pyFiles</td><td></td></tr><tr><td>spark.ui.showConsoleProgress</td><td>true</td></tr>
      </tbody>
    <tfoot></tfoot></table>
        </div>
        <span class="collapse-aggregated-hadoopProperties collapse-table" onclick="collapseTable('collapse-aggregated-hadoopProperties',
            'aggregated-hadoopProperties')">
          <h4>
            <span class="collapse-table-arrow arrow-open"></span>
            <a>Hadoop Properties</a>
          </h4>
        </span>
        <div class="aggregated-hadoopProperties collapsible-table">
          <table class="table table-bordered table-condensed table-striped sortable">
      <thead><tr><th class="sorttable_alpha" width="50.0%">Name</th><th class="sorttable_alpha" width="50.0%">Value</th></tr></thead>
      <tbody>
        <tr><td>dfs.ha.fencing.ssh.connect-timeout</td><td>30000</td></tr><tr><td>file.blocksize</td><td>67108864</td></tr><tr><td>file.bytes-per-checksum</td><td>512</td></tr><tr><td>file.client-write-packet-size</td><td>65536</td></tr><tr><td>file.replication</td><td>1</td></tr><tr><td>file.stream-buffer-size</td><td>4096</td></tr><tr><td>fs.AbstractFileSystem.file.impl</td><td>org.apache.hadoop.fs.local.LocalFs</td></tr><tr><td>fs.AbstractFileSystem.ftp.impl</td><td>org.apache.hadoop.fs.ftp.FtpFs</td></tr><tr><td>fs.AbstractFileSystem.har.impl</td><td>org.apache.hadoop.fs.HarFs</td></tr><tr><td>fs.AbstractFileSystem.hdfs.impl</td><td>org.apache.hadoop.fs.Hdfs</td></tr><tr><td>fs.AbstractFileSystem.viewfs.impl</td><td>org.apache.hadoop.fs.viewfs.ViewFs</td></tr><tr><td>fs.automatic.close</td><td>true</td></tr><tr><td>fs.client.resolve.remote.symlinks</td><td>true</td></tr><tr><td>fs.defaultFS</td><td>file:///</td></tr><tr><td>fs.df.interval</td><td>60000</td></tr><tr><td>fs.du.interval</td><td>600000</td></tr><tr><td>fs.ftp.host</td><td>0.0.0.0</td></tr><tr><td>fs.ftp.host.port</td><td>21</td></tr><tr><td>fs.har.impl.disable.cache</td><td>true</td></tr><tr><td>fs.permissions.umask-mode</td><td>022</td></tr><tr><td>fs.s3.block.size</td><td>67108864</td></tr><tr><td>fs.s3.buffer.dir</td><td>${hadoop.tmp.dir}/s3</td></tr><tr><td>fs.s3.maxRetries</td><td>4</td></tr><tr><td>fs.s3.sleepTimeSeconds</td><td>10</td></tr><tr><td>fs.s3a.attempts.maximum</td><td>10</td></tr><tr><td>fs.s3a.buffer.dir</td><td>${hadoop.tmp.dir}/s3a</td></tr><tr><td>fs.s3a.connection.establish.timeout</td><td>5000</td></tr><tr><td>fs.s3a.connection.maximum</td><td>15</td></tr><tr><td>fs.s3a.connection.ssl.enabled</td><td>true</td></tr><tr><td>fs.s3a.connection.timeout</td><td>50000</td></tr><tr><td>fs.s3a.fast.buffer.size</td><td>1048576</td></tr><tr><td>fs.s3a.fast.upload</td><td>false</td></tr><tr><td>fs.s3a.impl</td><td>org.apache.hadoop.fs.s3a.S3AFileSystem</td></tr><tr><td>fs.s3a.max.total.tasks</td><td>1000</td></tr><tr><td>fs.s3a.multipart.purge</td><td>false</td></tr><tr><td>fs.s3a.multipart.purge.age</td><td>86400</td></tr><tr><td>fs.s3a.multipart.size</td><td>104857600</td></tr><tr><td>fs.s3a.multipart.threshold</td><td>2147483647</td></tr><tr><td>fs.s3a.paging.maximum</td><td>5000</td></tr><tr><td>fs.s3a.threads.core</td><td>15</td></tr><tr><td>fs.s3a.threads.keepalivetime</td><td>60</td></tr><tr><td>fs.s3a.threads.max</td><td>256</td></tr><tr><td>fs.s3n.block.size</td><td>67108864</td></tr><tr><td>fs.s3n.multipart.copy.block.size</td><td>5368709120</td></tr><tr><td>fs.s3n.multipart.uploads.block.size</td><td>67108864</td></tr><tr><td>fs.s3n.multipart.uploads.enabled</td><td>false</td></tr><tr><td>fs.swift.impl</td><td>org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem</td></tr><tr><td>fs.trash.checkpoint.interval</td><td>0</td></tr><tr><td>fs.trash.interval</td><td>0</td></tr><tr><td>ftp.blocksize</td><td>67108864</td></tr><tr><td>ftp.bytes-per-checksum</td><td>512</td></tr><tr><td>ftp.client-write-packet-size</td><td>65536</td></tr><tr><td>ftp.replication</td><td>3</td></tr><tr><td>ftp.stream-buffer-size</td><td>4096</td></tr><tr><td>ha.failover-controller.cli-check.rpc-timeout.ms</td><td>20000</td></tr><tr><td>ha.failover-controller.graceful-fence.connection.retries</td><td>1</td></tr><tr><td>ha.failover-controller.graceful-fence.rpc-timeout.ms</td><td>5000</td></tr><tr><td>ha.failover-controller.new-active.rpc-timeout.ms</td><td>60000</td></tr><tr><td>ha.health-monitor.check-interval.ms</td><td>1000</td></tr><tr><td>ha.health-monitor.connect-retry-interval.ms</td><td>1000</td></tr><tr><td>ha.health-monitor.rpc-timeout.ms</td><td>45000</td></tr><tr><td>ha.health-monitor.sleep-after-disconnect.ms</td><td>1000</td></tr><tr><td>ha.zookeeper.acl</td><td>world:anyone:rwcda</td></tr><tr><td>ha.zookeeper.parent-znode</td><td>/hadoop-ha</td></tr><tr><td>ha.zookeeper.session-timeout.ms</td><td>5000</td></tr><tr><td>hadoop.common.configuration.version</td><td>0.23.0</td></tr><tr><td>hadoop.http.authentication.kerberos.keytab</td><td>${user.home}/hadoop.keytab</td></tr><tr><td>hadoop.http.authentication.kerberos.principal</td><td>HTTP/_HOST@LOCALHOST</td></tr><tr><td>hadoop.http.authentication.signature.secret.file</td><td>*********(redacted)</td></tr><tr><td>hadoop.http.authentication.simple.anonymous.allowed</td><td>true</td></tr><tr><td>hadoop.http.authentication.token.validity</td><td>*********(redacted)</td></tr><tr><td>hadoop.http.authentication.type</td><td>simple</td></tr><tr><td>hadoop.http.cross-origin.allowed-headers</td><td>X-Requested-With,Content-Type,Accept,Origin</td></tr><tr><td>hadoop.http.cross-origin.allowed-methods</td><td>GET,POST,HEAD</td></tr><tr><td>hadoop.http.cross-origin.allowed-origins</td><td>*</td></tr><tr><td>hadoop.http.cross-origin.enabled</td><td>false</td></tr><tr><td>hadoop.http.cross-origin.max-age</td><td>1800</td></tr><tr><td>hadoop.http.filter.initializers</td><td>org.apache.hadoop.http.lib.StaticUserWebFilter</td></tr><tr><td>hadoop.http.staticuser.user</td><td>dr.who</td></tr><tr><td>hadoop.jetty.logs.serve.aliases</td><td>true</td></tr><tr><td>hadoop.kerberos.kinit.command</td><td>kinit</td></tr><tr><td>hadoop.registry.jaas.context</td><td>Client</td></tr><tr><td>hadoop.registry.rm.enabled</td><td>false</td></tr><tr><td>hadoop.registry.secure</td><td>false</td></tr><tr><td>hadoop.registry.system.acls</td><td>sasl:yarn@, sasl:mapred@, sasl:hdfs@</td></tr><tr><td>hadoop.registry.zk.connection.timeout.ms</td><td>15000</td></tr><tr><td>hadoop.registry.zk.quorum</td><td>localhost:2181</td></tr><tr><td>hadoop.registry.zk.retry.ceiling.ms</td><td>60000</td></tr><tr><td>hadoop.registry.zk.retry.interval.ms</td><td>1000</td></tr><tr><td>hadoop.registry.zk.retry.times</td><td>5</td></tr><tr><td>hadoop.registry.zk.root</td><td>/registry</td></tr><tr><td>hadoop.registry.zk.session.timeout.ms</td><td>60000</td></tr><tr><td>hadoop.rpc.protection</td><td>authentication</td></tr><tr><td>hadoop.rpc.socket.factory.class.default</td><td>org.apache.hadoop.net.StandardSocketFactory</td></tr><tr><td>hadoop.security.authentication</td><td>simple</td></tr><tr><td>hadoop.security.authorization</td><td>false</td></tr><tr><td>hadoop.security.crypto.buffer.size</td><td>8192</td></tr><tr><td>hadoop.security.crypto.cipher.suite</td><td>AES/CTR/NoPadding</td></tr><tr><td>hadoop.security.crypto.codec.classes.aes.ctr.nopadding</td><td>org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec</td></tr><tr><td>hadoop.security.group.mapping</td><td>org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback</td></tr><tr><td>hadoop.security.group.mapping.ldap.directory.search.timeout</td><td>10000</td></tr><tr><td>hadoop.security.group.mapping.ldap.search.attr.group.name</td><td>cn</td></tr><tr><td>hadoop.security.group.mapping.ldap.search.attr.member</td><td>member</td></tr><tr><td>hadoop.security.group.mapping.ldap.search.filter.group</td><td>(objectClass=group)</td></tr><tr><td>hadoop.security.group.mapping.ldap.search.filter.user</td><td>(&amp;(objectClass=user)(sAMAccountName={0}))</td></tr><tr><td>hadoop.security.group.mapping.ldap.ssl</td><td>false</td></tr><tr><td>hadoop.security.groups.cache.secs</td><td>300</td></tr><tr><td>hadoop.security.groups.cache.warn.after.ms</td><td>5000</td></tr><tr><td>hadoop.security.groups.negative-cache.secs</td><td>30</td></tr><tr><td>hadoop.security.instrumentation.requires.admin</td><td>false</td></tr><tr><td>hadoop.security.java.secure.random.algorithm</td><td>SHA1PRNG</td></tr><tr><td>hadoop.security.kms.client.authentication.retry-count</td><td>1</td></tr><tr><td>hadoop.security.kms.client.encrypted.key.cache.expiry</td><td>43200000</td></tr><tr><td>hadoop.security.kms.client.encrypted.key.cache.low-watermark</td><td>0.3f</td></tr><tr><td>hadoop.security.kms.client.encrypted.key.cache.num.refill.threads</td><td>2</td></tr><tr><td>hadoop.security.kms.client.encrypted.key.cache.size</td><td>500</td></tr><tr><td>hadoop.security.random.device.file.path</td><td>/dev/urandom</td></tr><tr><td>hadoop.security.sensitive-config-keys</td><td>*********(redacted)</td></tr><tr><td>hadoop.security.uid.cache.secs</td><td>14400</td></tr><tr><td>hadoop.ssl.client.conf</td><td>ssl-client.xml</td></tr><tr><td>hadoop.ssl.enabled</td><td>false</td></tr><tr><td>hadoop.ssl.enabled.protocols</td><td>TLSv1</td></tr><tr><td>hadoop.ssl.hostname.verifier</td><td>DEFAULT</td></tr><tr><td>hadoop.ssl.keystores.factory.class</td><td>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</td></tr><tr><td>hadoop.ssl.require.client.cert</td><td>false</td></tr><tr><td>hadoop.ssl.server.conf</td><td>ssl-server.xml</td></tr><tr><td>hadoop.tmp.dir</td><td>/tmp/hadoop-${user.name}</td></tr><tr><td>hadoop.user.group.static.mapping.overrides</td><td>dr.who=;</td></tr><tr><td>hadoop.util.hash.type</td><td>murmur</td></tr><tr><td>hadoop.work.around.non.threadsafe.getpwuid</td><td>false</td></tr><tr><td>io.bytes.per.checksum</td><td>512</td></tr><tr><td>io.compression.codec.bzip2.library</td><td>system-native</td></tr><tr><td>io.file.buffer.size</td><td>65536</td></tr><tr><td>io.map.index.interval</td><td>128</td></tr><tr><td>io.map.index.skip</td><td>0</td></tr><tr><td>io.mapfile.bloom.error.rate</td><td>0.005</td></tr><tr><td>io.mapfile.bloom.size</td><td>1048576</td></tr><tr><td>io.native.lib.available</td><td>true</td></tr><tr><td>io.seqfile.compress.blocksize</td><td>1000000</td></tr><tr><td>io.seqfile.lazydecompress</td><td>true</td></tr><tr><td>io.seqfile.local.dir</td><td>${hadoop.tmp.dir}/io/local</td></tr><tr><td>io.seqfile.sorter.recordlimit</td><td>1000000</td></tr><tr><td>io.serializations</td><td>org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization</td></tr><tr><td>io.skip.checksum.errors</td><td>false</td></tr><tr><td>ipc.client.connect.max.retries</td><td>10</td></tr><tr><td>ipc.client.connect.max.retries.on.timeouts</td><td>45</td></tr><tr><td>ipc.client.connect.retry.interval</td><td>1000</td></tr><tr><td>ipc.client.connect.timeout</td><td>20000</td></tr><tr><td>ipc.client.connection.maxidletime</td><td>10000</td></tr><tr><td>ipc.client.fallback-to-simple-auth-allowed</td><td>false</td></tr><tr><td>ipc.client.idlethreshold</td><td>4000</td></tr><tr><td>ipc.client.kill.max</td><td>10</td></tr><tr><td>ipc.client.ping</td><td>true</td></tr><tr><td>ipc.client.rpc-timeout.ms</td><td>0</td></tr><tr><td>ipc.maximum.data.length</td><td>67108864</td></tr><tr><td>ipc.ping.interval</td><td>60000</td></tr><tr><td>ipc.server.listen.queue.size</td><td>128</td></tr><tr><td>ipc.server.log.slow.rpc</td><td>false</td></tr><tr><td>ipc.server.max.connections</td><td>0</td></tr><tr><td>map.sort.class</td><td>org.apache.hadoop.util.QuickSort</td></tr><tr><td>mapred.child.java.opts</td><td>-Xmx200m</td></tr><tr><td>mapreduce.am.max-attempts</td><td>2</td></tr><tr><td>mapreduce.app-submission.cross-platform</td><td>false</td></tr><tr><td>mapreduce.client.completion.pollinterval</td><td>5000</td></tr><tr><td>mapreduce.client.output.filter</td><td>FAILED</td></tr><tr><td>mapreduce.client.progressmonitor.pollinterval</td><td>1000</td></tr><tr><td>mapreduce.client.submit.file.replication</td><td>10</td></tr><tr><td>mapreduce.cluster.acls.enabled</td><td>false</td></tr><tr><td>mapreduce.cluster.local.dir</td><td>${hadoop.tmp.dir}/mapred/local</td></tr><tr><td>mapreduce.cluster.temp.dir</td><td>${hadoop.tmp.dir}/mapred/temp</td></tr><tr><td>mapreduce.fileoutputcommitter.algorithm.version</td><td>1</td></tr><tr><td>mapreduce.framework.name</td><td>local</td></tr><tr><td>mapreduce.ifile.readahead</td><td>true</td></tr><tr><td>mapreduce.ifile.readahead.bytes</td><td>4194304</td></tr><tr><td>mapreduce.input.fileinputformat.list-status.num-threads</td><td>1</td></tr><tr><td>mapreduce.input.fileinputformat.split.minsize</td><td>0</td></tr><tr><td>mapreduce.input.lineinputformat.linespermap</td><td>1</td></tr><tr><td>mapreduce.job.acl-modify-job</td><td> </td></tr><tr><td>mapreduce.job.acl-view-job</td><td> </td></tr><tr><td>mapreduce.job.classloader</td><td>false</td></tr><tr><td>mapreduce.job.committer.setup.cleanup.needed</td><td>true</td></tr><tr><td>mapreduce.job.complete.cancel.delegation.tokens</td><td>*********(redacted)</td></tr><tr><td>mapreduce.job.counters.max</td><td>120</td></tr><tr><td>mapreduce.job.emit-timeline-data</td><td>false</td></tr><tr><td>mapreduce.job.end-notification.max.attempts</td><td>5</td></tr><tr><td>mapreduce.job.end-notification.max.retry.interval</td><td>5000</td></tr><tr><td>mapreduce.job.end-notification.retry.attempts</td><td>0</td></tr><tr><td>mapreduce.job.end-notification.retry.interval</td><td>1000</td></tr><tr><td>mapreduce.job.hdfs-servers</td><td>${fs.defaultFS}</td></tr><tr><td>mapreduce.job.jvm.numtasks</td><td>1</td></tr><tr><td>mapreduce.job.map.output.collector.class</td><td>org.apache.hadoop.mapred.MapTask$MapOutputBuffer</td></tr><tr><td>mapreduce.job.maps</td><td>2</td></tr><tr><td>mapreduce.job.max.split.locations</td><td>10</td></tr><tr><td>mapreduce.job.maxtaskfailures.per.tracker</td><td>3</td></tr><tr><td>mapreduce.job.queuename</td><td>default</td></tr><tr><td>mapreduce.job.reduce.shuffle.consumer.plugin.class</td><td>org.apache.hadoop.mapreduce.task.reduce.Shuffle</td></tr><tr><td>mapreduce.job.reduce.slowstart.completedmaps</td><td>0.05</td></tr><tr><td>mapreduce.job.reducer.preempt.delay.sec</td><td>0</td></tr><tr><td>mapreduce.job.reducer.unconditional-preempt.delay.sec</td><td>300</td></tr><tr><td>mapreduce.job.reduces</td><td>1</td></tr><tr><td>mapreduce.job.running.map.limit</td><td>0</td></tr><tr><td>mapreduce.job.running.reduce.limit</td><td>0</td></tr><tr><td>mapreduce.job.speculative.minimum-allowed-tasks</td><td>10</td></tr><tr><td>mapreduce.job.speculative.retry-after-no-speculate</td><td>1000</td></tr><tr><td>mapreduce.job.speculative.retry-after-speculate</td><td>15000</td></tr><tr><td>mapreduce.job.speculative.slowtaskthreshold</td><td>1.0</td></tr><tr><td>mapreduce.job.speculative.speculative-cap-running-tasks</td><td>0.1</td></tr><tr><td>mapreduce.job.speculative.speculative-cap-total-tasks</td><td>0.01</td></tr><tr><td>mapreduce.job.split.metainfo.maxsize</td><td>10000000</td></tr><tr><td>mapreduce.job.token.tracking.ids.enabled</td><td>*********(redacted)</td></tr><tr><td>mapreduce.job.ubertask.enable</td><td>false</td></tr><tr><td>mapreduce.job.ubertask.maxmaps</td><td>9</td></tr><tr><td>mapreduce.job.ubertask.maxreduces</td><td>1</td></tr><tr><td>mapreduce.job.userlog.retain.hours</td><td>24</td></tr><tr><td>mapreduce.jobhistory.address</td><td>0.0.0.0:10020</td></tr><tr><td>mapreduce.jobhistory.admin.acl</td><td>*</td></tr><tr><td>mapreduce.jobhistory.admin.address</td><td>0.0.0.0:10033</td></tr><tr><td>mapreduce.jobhistory.cleaner.enable</td><td>true</td></tr><tr><td>mapreduce.jobhistory.cleaner.interval-ms</td><td>86400000</td></tr><tr><td>mapreduce.jobhistory.client.thread-count</td><td>10</td></tr><tr><td>mapreduce.jobhistory.datestring.cache.size</td><td>200000</td></tr><tr><td>mapreduce.jobhistory.done-dir</td><td>${yarn.app.mapreduce.am.staging-dir}/history/done</td></tr><tr><td>mapreduce.jobhistory.http.policy</td><td>HTTP_ONLY</td></tr><tr><td>mapreduce.jobhistory.intermediate-done-dir</td><td>${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate</td></tr><tr><td>mapreduce.jobhistory.joblist.cache.size</td><td>20000</td></tr><tr><td>mapreduce.jobhistory.keytab</td><td>/etc/security/keytab/jhs.service.keytab</td></tr><tr><td>mapreduce.jobhistory.loadedjobs.cache.size</td><td>5</td></tr><tr><td>mapreduce.jobhistory.max-age-ms</td><td>604800000</td></tr><tr><td>mapreduce.jobhistory.minicluster.fixed.ports</td><td>false</td></tr><tr><td>mapreduce.jobhistory.move.interval-ms</td><td>180000</td></tr><tr><td>mapreduce.jobhistory.move.thread-count</td><td>3</td></tr><tr><td>mapreduce.jobhistory.principal</td><td>jhs/_HOST@REALM.TLD</td></tr><tr><td>mapreduce.jobhistory.recovery.enable</td><td>false</td></tr><tr><td>mapreduce.jobhistory.recovery.store.class</td><td>org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService</td></tr><tr><td>mapreduce.jobhistory.recovery.store.fs.uri</td><td>${hadoop.tmp.dir}/mapred/history/recoverystore</td></tr><tr><td>mapreduce.jobhistory.recovery.store.leveldb.path</td><td>${hadoop.tmp.dir}/mapred/history/recoverystore</td></tr><tr><td>mapreduce.jobhistory.webapp.address</td><td>0.0.0.0:19888</td></tr><tr><td>mapreduce.jobtracker.address</td><td>local</td></tr><tr><td>mapreduce.jobtracker.expire.trackers.interval</td><td>600000</td></tr><tr><td>mapreduce.jobtracker.handler.count</td><td>10</td></tr><tr><td>mapreduce.jobtracker.heartbeats.in.second</td><td>100</td></tr><tr><td>mapreduce.jobtracker.http.address</td><td>0.0.0.0:50030</td></tr><tr><td>mapreduce.jobtracker.instrumentation</td><td>org.apache.hadoop.mapred.JobTrackerMetricsInst</td></tr><tr><td>mapreduce.jobtracker.jobhistory.block.size</td><td>3145728</td></tr><tr><td>mapreduce.jobtracker.jobhistory.lru.cache.size</td><td>5</td></tr><tr><td>mapreduce.jobtracker.jobhistory.task.numberprogresssplits</td><td>12</td></tr><tr><td>mapreduce.jobtracker.maxtasks.perjob</td><td>-1</td></tr><tr><td>mapreduce.jobtracker.persist.jobstatus.active</td><td>true</td></tr><tr><td>mapreduce.jobtracker.persist.jobstatus.dir</td><td>/jobtracker/jobsInfo</td></tr><tr><td>mapreduce.jobtracker.persist.jobstatus.hours</td><td>1</td></tr><tr><td>mapreduce.jobtracker.restart.recover</td><td>false</td></tr><tr><td>mapreduce.jobtracker.retiredjobs.cache.size</td><td>1000</td></tr><tr><td>mapreduce.jobtracker.staging.root.dir</td><td>${hadoop.tmp.dir}/mapred/staging</td></tr><tr><td>mapreduce.jobtracker.system.dir</td><td>${hadoop.tmp.dir}/mapred/system</td></tr><tr><td>mapreduce.jobtracker.taskcache.levels</td><td>2</td></tr><tr><td>mapreduce.jobtracker.taskscheduler</td><td>org.apache.hadoop.mapred.JobQueueTaskScheduler</td></tr><tr><td>mapreduce.jobtracker.tasktracker.maxblacklists</td><td>4</td></tr><tr><td>mapreduce.local.clientfactory.class.name</td><td>org.apache.hadoop.mapred.LocalClientFactory</td></tr><tr><td>mapreduce.map.cpu.vcores</td><td>1</td></tr><tr><td>mapreduce.map.log.level</td><td>INFO</td></tr><tr><td>mapreduce.map.maxattempts</td><td>4</td></tr><tr><td>mapreduce.map.memory.mb</td><td>1024</td></tr><tr><td>mapreduce.map.output.compress</td><td>false</td></tr><tr><td>mapreduce.map.output.compress.codec</td><td>org.apache.hadoop.io.compress.DefaultCodec</td></tr><tr><td>mapreduce.map.skip.maxrecords</td><td>0</td></tr><tr><td>mapreduce.map.skip.proc.count.autoincr</td><td>true</td></tr><tr><td>mapreduce.map.sort.spill.percent</td><td>0.80</td></tr><tr><td>mapreduce.map.speculative</td><td>true</td></tr><tr><td>mapreduce.output.fileoutputformat.compress</td><td>false</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.codec</td><td>org.apache.hadoop.io.compress.DefaultCodec</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.type</td><td>RECORD</td></tr><tr><td>mapreduce.reduce.cpu.vcores</td><td>1</td></tr><tr><td>mapreduce.reduce.input.buffer.percent</td><td>0.0</td></tr><tr><td>mapreduce.reduce.log.level</td><td>INFO</td></tr><tr><td>mapreduce.reduce.markreset.buffer.percent</td><td>0.0</td></tr><tr><td>mapreduce.reduce.maxattempts</td><td>4</td></tr><tr><td>mapreduce.reduce.memory.mb</td><td>1024</td></tr><tr><td>mapreduce.reduce.merge.inmem.threshold</td><td>1000</td></tr><tr><td>mapreduce.reduce.shuffle.connect.timeout</td><td>180000</td></tr><tr><td>mapreduce.reduce.shuffle.fetch.retry.enabled</td><td>${yarn.nodemanager.recovery.enabled}</td></tr><tr><td>mapreduce.reduce.shuffle.fetch.retry.interval-ms</td><td>1000</td></tr><tr><td>mapreduce.reduce.shuffle.fetch.retry.timeout-ms</td><td>30000</td></tr><tr><td>mapreduce.reduce.shuffle.input.buffer.percent</td><td>0.70</td></tr><tr><td>mapreduce.reduce.shuffle.memory.limit.percent</td><td>0.25</td></tr><tr><td>mapreduce.reduce.shuffle.merge.percent</td><td>0.66</td></tr><tr><td>mapreduce.reduce.shuffle.parallelcopies</td><td>5</td></tr><tr><td>mapreduce.reduce.shuffle.read.timeout</td><td>180000</td></tr><tr><td>mapreduce.reduce.shuffle.retry-delay.max.ms</td><td>60000</td></tr><tr><td>mapreduce.reduce.skip.maxgroups</td><td>0</td></tr><tr><td>mapreduce.reduce.skip.proc.count.autoincr</td><td>true</td></tr><tr><td>mapreduce.reduce.speculative</td><td>true</td></tr><tr><td>mapreduce.shuffle.connection-keep-alive.enable</td><td>false</td></tr><tr><td>mapreduce.shuffle.connection-keep-alive.timeout</td><td>5</td></tr><tr><td>mapreduce.shuffle.listen.queue.size</td><td>128</td></tr><tr><td>mapreduce.shuffle.max.connections</td><td>0</td></tr><tr><td>mapreduce.shuffle.max.threads</td><td>0</td></tr><tr><td>mapreduce.shuffle.port</td><td>13562</td></tr><tr><td>mapreduce.shuffle.ssl.enabled</td><td>false</td></tr><tr><td>mapreduce.shuffle.ssl.file.buffer.size</td><td>65536</td></tr><tr><td>mapreduce.shuffle.transfer.buffer.size</td><td>131072</td></tr><tr><td>mapreduce.task.combine.progress.records</td><td>10000</td></tr><tr><td>mapreduce.task.files.preserve.failedtasks</td><td>false</td></tr><tr><td>mapreduce.task.io.sort.factor</td><td>10</td></tr><tr><td>mapreduce.task.io.sort.mb</td><td>100</td></tr><tr><td>mapreduce.task.merge.progress.records</td><td>10000</td></tr><tr><td>mapreduce.task.profile</td><td>false</td></tr><tr><td>mapreduce.task.profile.map.params</td><td>${mapreduce.task.profile.params}</td></tr><tr><td>mapreduce.task.profile.maps</td><td>0-2</td></tr><tr><td>mapreduce.task.profile.params</td><td>-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s</td></tr><tr><td>mapreduce.task.profile.reduce.params</td><td>${mapreduce.task.profile.params}</td></tr><tr><td>mapreduce.task.profile.reduces</td><td>0-2</td></tr><tr><td>mapreduce.task.skip.start.attempts</td><td>2</td></tr><tr><td>mapreduce.task.timeout</td><td>600000</td></tr><tr><td>mapreduce.task.userlog.limit.kb</td><td>0</td></tr><tr><td>mapreduce.tasktracker.dns.interface</td><td>default</td></tr><tr><td>mapreduce.tasktracker.dns.nameserver</td><td>default</td></tr><tr><td>mapreduce.tasktracker.healthchecker.interval</td><td>60000</td></tr><tr><td>mapreduce.tasktracker.healthchecker.script.timeout</td><td>600000</td></tr><tr><td>mapreduce.tasktracker.http.address</td><td>0.0.0.0:50060</td></tr><tr><td>mapreduce.tasktracker.http.threads</td><td>40</td></tr><tr><td>mapreduce.tasktracker.indexcache.mb</td><td>10</td></tr><tr><td>mapreduce.tasktracker.instrumentation</td><td>org.apache.hadoop.mapred.TaskTrackerMetricsInst</td></tr><tr><td>mapreduce.tasktracker.local.dir.minspacekill</td><td>0</td></tr><tr><td>mapreduce.tasktracker.local.dir.minspacestart</td><td>0</td></tr><tr><td>mapreduce.tasktracker.map.tasks.maximum</td><td>2</td></tr><tr><td>mapreduce.tasktracker.outofband.heartbeat</td><td>false</td></tr><tr><td>mapreduce.tasktracker.reduce.tasks.maximum</td><td>2</td></tr><tr><td>mapreduce.tasktracker.report.address</td><td>127.0.0.1:0</td></tr><tr><td>mapreduce.tasktracker.taskcontroller</td><td>org.apache.hadoop.mapred.DefaultTaskController</td></tr><tr><td>mapreduce.tasktracker.taskmemorymanager.monitoringinterval</td><td>5000</td></tr><tr><td>mapreduce.tasktracker.tasks.sleeptimebeforesigkill</td><td>5000</td></tr><tr><td>net.topology.impl</td><td>org.apache.hadoop.net.NetworkTopology</td></tr><tr><td>net.topology.node.switch.mapping.impl</td><td>org.apache.hadoop.net.ScriptBasedMapping</td></tr><tr><td>net.topology.script.number.args</td><td>100</td></tr><tr><td>nfs.exports.allowed.hosts</td><td>* rw</td></tr><tr><td>rpc.metrics.quantile.enable</td><td>false</td></tr><tr><td>s3.blocksize</td><td>67108864</td></tr><tr><td>s3.bytes-per-checksum</td><td>512</td></tr><tr><td>s3.client-write-packet-size</td><td>65536</td></tr><tr><td>s3.replication</td><td>3</td></tr><tr><td>s3.stream-buffer-size</td><td>4096</td></tr><tr><td>s3native.blocksize</td><td>67108864</td></tr><tr><td>s3native.bytes-per-checksum</td><td>512</td></tr><tr><td>s3native.client-write-packet-size</td><td>65536</td></tr><tr><td>s3native.replication</td><td>3</td></tr><tr><td>s3native.stream-buffer-size</td><td>4096</td></tr><tr><td>tfile.fs.input.buffer.size</td><td>262144</td></tr><tr><td>tfile.fs.output.buffer.size</td><td>262144</td></tr><tr><td>tfile.io.chunk.size</td><td>1048576</td></tr><tr><td>yarn.acl.enable</td><td>false</td></tr><tr><td>yarn.admin.acl</td><td>*</td></tr><tr><td>yarn.am.liveness-monitor.expiry-interval-ms</td><td>600000</td></tr><tr><td>yarn.app.mapreduce.am.command-opts</td><td>-Xmx1024m</td></tr><tr><td>yarn.app.mapreduce.am.container.log.backups</td><td>0</td></tr><tr><td>yarn.app.mapreduce.am.container.log.limit.kb</td><td>0</td></tr><tr><td>yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size</td><td>10</td></tr><tr><td>yarn.app.mapreduce.am.hard-kill-timeout-ms</td><td>10000</td></tr><tr><td>yarn.app.mapreduce.am.job.committer.cancel-timeout</td><td>60000</td></tr><tr><td>yarn.app.mapreduce.am.job.committer.commit-window</td><td>10000</td></tr><tr><td>yarn.app.mapreduce.am.job.task.listener.thread-count</td><td>30</td></tr><tr><td>yarn.app.mapreduce.am.resource.cpu-vcores</td><td>1</td></tr><tr><td>yarn.app.mapreduce.am.resource.mb</td><td>1536</td></tr><tr><td>yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms</td><td>1000</td></tr><tr><td>yarn.app.mapreduce.am.staging-dir</td><td>/tmp/hadoop-yarn/staging</td></tr><tr><td>yarn.app.mapreduce.client-am.ipc.max-retries</td><td>3</td></tr><tr><td>yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts</td><td>3</td></tr><tr><td>yarn.app.mapreduce.client.job.max-retries</td><td>0</td></tr><tr><td>yarn.app.mapreduce.client.job.retry-interval</td><td>2000</td></tr><tr><td>yarn.app.mapreduce.client.max-retries</td><td>3</td></tr><tr><td>yarn.app.mapreduce.shuffle.log.backups</td><td>0</td></tr><tr><td>yarn.app.mapreduce.shuffle.log.limit.kb</td><td>0</td></tr><tr><td>yarn.app.mapreduce.shuffle.log.separate</td><td>true</td></tr><tr><td>yarn.app.mapreduce.task.container.log.backups</td><td>0</td></tr><tr><td>yarn.client.application-client-protocol.poll-interval-ms</td><td>200</td></tr><tr><td>yarn.client.failover-proxy-provider</td><td>org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider</td></tr><tr><td>yarn.client.failover-retries</td><td>0</td></tr><tr><td>yarn.client.failover-retries-on-socket-timeouts</td><td>0</td></tr><tr><td>yarn.client.max-cached-nodemanagers-proxies</td><td>0</td></tr><tr><td>yarn.client.nodemanager-client-async.thread-pool-max-size</td><td>500</td></tr><tr><td>yarn.client.nodemanager-connect.max-wait-ms</td><td>180000</td></tr><tr><td>yarn.client.nodemanager-connect.retry-interval-ms</td><td>10000</td></tr><tr><td>yarn.dispatcher.drain-events.timeout</td><td>300000</td></tr><tr><td>yarn.fail-fast</td><td>false</td></tr><tr><td>yarn.http.policy</td><td>HTTP_ONLY</td></tr><tr><td>yarn.ipc.rpc.class</td><td>org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC</td></tr><tr><td>yarn.log-aggregation-enable</td><td>false</td></tr><tr><td>yarn.log-aggregation.retain-check-interval-seconds</td><td>-1</td></tr><tr><td>yarn.log-aggregation.retain-seconds</td><td>-1</td></tr><tr><td>yarn.nm.liveness-monitor.expiry-interval-ms</td><td>600000</td></tr><tr><td>yarn.nodemanager.address</td><td>${yarn.nodemanager.hostname}:0</td></tr><tr><td>yarn.nodemanager.admin-env</td><td>MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX</td></tr><tr><td>yarn.nodemanager.aux-services.mapreduce_shuffle.class</td><td>org.apache.hadoop.mapred.ShuffleHandler</td></tr><tr><td>yarn.nodemanager.container-executor.class</td><td>org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor</td></tr><tr><td>yarn.nodemanager.container-manager.thread-count</td><td>20</td></tr><tr><td>yarn.nodemanager.container-metrics.unregister-delay-ms</td><td>10000</td></tr><tr><td>yarn.nodemanager.container-monitor.interval-ms</td><td>3000</td></tr><tr><td>yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled</td><td>false</td></tr><tr><td>yarn.nodemanager.delete.debug-delay-sec</td><td>0</td></tr><tr><td>yarn.nodemanager.delete.thread-count</td><td>4</td></tr><tr><td>yarn.nodemanager.disk-health-checker.interval-ms</td><td>120000</td></tr><tr><td>yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage</td><td>90.0</td></tr><tr><td>yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb</td><td>0</td></tr><tr><td>yarn.nodemanager.disk-health-checker.min-healthy-disks</td><td>0.25</td></tr><tr><td>yarn.nodemanager.docker-container-executor.exec-name</td><td>/usr/bin/docker</td></tr><tr><td>yarn.nodemanager.env-whitelist</td><td>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME</td></tr><tr><td>yarn.nodemanager.health-checker.interval-ms</td><td>600000</td></tr><tr><td>yarn.nodemanager.health-checker.script.timeout-ms</td><td>1200000</td></tr><tr><td>yarn.nodemanager.hostname</td><td>0.0.0.0</td></tr><tr><td>yarn.nodemanager.keytab</td><td>/etc/krb5.keytab</td></tr><tr><td>yarn.nodemanager.linux-container-executor.cgroups.hierarchy</td><td>/hadoop-yarn</td></tr><tr><td>yarn.nodemanager.linux-container-executor.cgroups.mount</td><td>false</td></tr><tr><td>yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage</td><td>false</td></tr><tr><td>yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users</td><td>true</td></tr><tr><td>yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user</td><td>nobody</td></tr><tr><td>yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern</td><td>^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$</td></tr><tr><td>yarn.nodemanager.linux-container-executor.resources-handler.class</td><td>org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler</td></tr><tr><td>yarn.nodemanager.local-cache.max-files-per-directory</td><td>8192</td></tr><tr><td>yarn.nodemanager.local-dirs</td><td>${hadoop.tmp.dir}/nm-local-dir</td></tr><tr><td>yarn.nodemanager.localizer.address</td><td>${yarn.nodemanager.hostname}:8040</td></tr><tr><td>yarn.nodemanager.localizer.cache.cleanup.interval-ms</td><td>600000</td></tr><tr><td>yarn.nodemanager.localizer.cache.target-size-mb</td><td>10240</td></tr><tr><td>yarn.nodemanager.localizer.client.thread-count</td><td>5</td></tr><tr><td>yarn.nodemanager.localizer.fetch.thread-count</td><td>4</td></tr><tr><td>yarn.nodemanager.log-aggregation.compression-type</td><td>none</td></tr><tr><td>yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds</td><td>-1</td></tr><tr><td>yarn.nodemanager.log-dirs</td><td>${yarn.log.dir}/userlogs</td></tr><tr><td>yarn.nodemanager.log.retain-seconds</td><td>10800</td></tr><tr><td>yarn.nodemanager.pmem-check-enabled</td><td>true</td></tr><tr><td>yarn.nodemanager.process-kill-wait.ms</td><td>2000</td></tr><tr><td>yarn.nodemanager.recovery.compaction-interval-secs</td><td>3600</td></tr><tr><td>yarn.nodemanager.recovery.dir</td><td>${hadoop.tmp.dir}/yarn-nm-recovery</td></tr><tr><td>yarn.nodemanager.recovery.enabled</td><td>false</td></tr><tr><td>yarn.nodemanager.remote-app-log-dir</td><td>/tmp/logs</td></tr><tr><td>yarn.nodemanager.remote-app-log-dir-suffix</td><td>logs</td></tr><tr><td>yarn.nodemanager.resource.cpu-vcores</td><td>8</td></tr><tr><td>yarn.nodemanager.resource.memory-mb</td><td>8192</td></tr><tr><td>yarn.nodemanager.resource.percentage-physical-cpu-limit</td><td>100</td></tr><tr><td>yarn.nodemanager.resourcemanager.minimum.version</td><td>NONE</td></tr><tr><td>yarn.nodemanager.sleep-delay-before-sigkill.ms</td><td>250</td></tr><tr><td>yarn.nodemanager.vmem-check-enabled</td><td>true</td></tr><tr><td>yarn.nodemanager.vmem-pmem-ratio</td><td>2.1</td></tr><tr><td>yarn.nodemanager.webapp.address</td><td>${yarn.nodemanager.hostname}:8042</td></tr><tr><td>yarn.nodemanager.webapp.cross-origin.enabled</td><td>false</td></tr><tr><td>yarn.nodemanager.windows-container.cpu-limit.enabled</td><td>false</td></tr><tr><td>yarn.nodemanager.windows-container.memory-limit.enabled</td><td>false</td></tr><tr><td>yarn.resourcemanager.address</td><td>${yarn.resourcemanager.hostname}:8032</td></tr><tr><td>yarn.resourcemanager.admin.address</td><td>${yarn.resourcemanager.hostname}:8033</td></tr><tr><td>yarn.resourcemanager.admin.client.thread-count</td><td>1</td></tr><tr><td>yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs</td><td>*********(redacted)</td></tr><tr><td>yarn.resourcemanager.am.max-attempts</td><td>2</td></tr><tr><td>yarn.resourcemanager.amlauncher.thread-count</td><td>50</td></tr><tr><td>yarn.resourcemanager.client.thread-count</td><td>50</td></tr><tr><td>yarn.resourcemanager.configuration.provider-class</td><td>org.apache.hadoop.yarn.LocalConfigurationProvider</td></tr><tr><td>yarn.resourcemanager.connect.max-wait.ms</td><td>900000</td></tr><tr><td>yarn.resourcemanager.connect.retry-interval.ms</td><td>30000</td></tr><tr><td>yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs</td><td>*********(redacted)</td></tr><tr><td>yarn.resourcemanager.container.liveness-monitor.interval-ms</td><td>600000</td></tr><tr><td>yarn.resourcemanager.delayed.delegation-token.removal-interval-ms</td><td>*********(redacted)</td></tr><tr><td>yarn.resourcemanager.fail-fast</td><td>${yarn.fail-fast}</td></tr><tr><td>yarn.resourcemanager.fs.state-store.num-retries</td><td>0</td></tr><tr><td>yarn.resourcemanager.fs.state-store.retry-interval-ms</td><td>1000</td></tr><tr><td>yarn.resourcemanager.fs.state-store.retry-policy-spec</td><td>2000, 500</td></tr><tr><td>yarn.resourcemanager.fs.state-store.uri</td><td>${hadoop.tmp.dir}/yarn/system/rmstore</td></tr><tr><td>yarn.resourcemanager.ha.automatic-failover.embedded</td><td>true</td></tr><tr><td>yarn.resourcemanager.ha.automatic-failover.enabled</td><td>true</td></tr><tr><td>yarn.resourcemanager.ha.automatic-failover.zk-base-path</td><td>/yarn-leader-election</td></tr><tr><td>yarn.resourcemanager.ha.enabled</td><td>false</td></tr><tr><td>yarn.resourcemanager.hostname</td><td>0.0.0.0</td></tr><tr><td>yarn.resourcemanager.keytab</td><td>/etc/krb5.keytab</td></tr><tr><td>yarn.resourcemanager.leveldb-state-store.compaction-interval-secs</td><td>3600</td></tr><tr><td>yarn.resourcemanager.leveldb-state-store.path</td><td>${hadoop.tmp.dir}/yarn/system/rmstore</td></tr><tr><td>yarn.resourcemanager.max-completed-applications</td><td>10000</td></tr><tr><td>yarn.resourcemanager.nodemanager-connect-retries</td><td>10</td></tr><tr><td>yarn.resourcemanager.nodemanager.minimum.version</td><td>NONE</td></tr><tr><td>yarn.resourcemanager.nodemanagers.heartbeat-interval-ms</td><td>1000</td></tr><tr><td>yarn.resourcemanager.proxy-user-privileges.enabled</td><td>false</td></tr><tr><td>yarn.resourcemanager.recovery.enabled</td><td>false</td></tr><tr><td>yarn.resourcemanager.resource-tracker.address</td><td>${yarn.resourcemanager.hostname}:8031</td></tr><tr><td>yarn.resourcemanager.resource-tracker.client.thread-count</td><td>50</td></tr><tr><td>yarn.resourcemanager.scheduler.address</td><td>${yarn.resourcemanager.hostname}:8030</td></tr><tr><td>yarn.resourcemanager.scheduler.class</td><td>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</td></tr><tr><td>yarn.resourcemanager.scheduler.client.thread-count</td><td>50</td></tr><tr><td>yarn.resourcemanager.scheduler.monitor.enable</td><td>false</td></tr><tr><td>yarn.resourcemanager.scheduler.monitor.policies</td><td>org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy</td></tr><tr><td>yarn.resourcemanager.state-store.max-completed-applications</td><td>${yarn.resourcemanager.max-completed-applications}</td></tr><tr><td>yarn.resourcemanager.store.class</td><td>org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore</td></tr><tr><td>yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size</td><td>10</td></tr><tr><td>yarn.resourcemanager.system-metrics-publisher.enabled</td><td>false</td></tr><tr><td>yarn.resourcemanager.webapp.address</td><td>${yarn.resourcemanager.hostname}:8088</td></tr><tr><td>yarn.resourcemanager.webapp.cross-origin.enabled</td><td>false</td></tr><tr><td>yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled</td><td>*********(redacted)</td></tr><tr><td>yarn.resourcemanager.webapp.https.address</td><td>${yarn.resourcemanager.hostname}:8090</td></tr><tr><td>yarn.resourcemanager.work-preserving-recovery.enabled</td><td>true</td></tr><tr><td>yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms</td><td>10000</td></tr><tr><td>yarn.resourcemanager.zk-acl</td><td>world:anyone:rwcda</td></tr><tr><td>yarn.resourcemanager.zk-num-retries</td><td>1000</td></tr><tr><td>yarn.resourcemanager.zk-retry-interval-ms</td><td>1000</td></tr><tr><td>yarn.resourcemanager.zk-state-store.parent-path</td><td>/rmstore</td></tr><tr><td>yarn.resourcemanager.zk-timeout-ms</td><td>10000</td></tr><tr><td>yarn.scheduler.maximum-allocation-mb</td><td>8192</td></tr><tr><td>yarn.scheduler.maximum-allocation-vcores</td><td>32</td></tr><tr><td>yarn.scheduler.minimum-allocation-mb</td><td>1024</td></tr><tr><td>yarn.scheduler.minimum-allocation-vcores</td><td>1</td></tr><tr><td>yarn.sharedcache.admin.address</td><td>0.0.0.0:8047</td></tr><tr><td>yarn.sharedcache.admin.thread-count</td><td>1</td></tr><tr><td>yarn.sharedcache.app-checker.class</td><td>org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker</td></tr><tr><td>yarn.sharedcache.checksum.algo.impl</td><td>org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl</td></tr><tr><td>yarn.sharedcache.cleaner.initial-delay-mins</td><td>10</td></tr><tr><td>yarn.sharedcache.cleaner.period-mins</td><td>1440</td></tr><tr><td>yarn.sharedcache.cleaner.resource-sleep-ms</td><td>0</td></tr><tr><td>yarn.sharedcache.client-server.address</td><td>0.0.0.0:8045</td></tr><tr><td>yarn.sharedcache.client-server.thread-count</td><td>50</td></tr><tr><td>yarn.sharedcache.enabled</td><td>false</td></tr><tr><td>yarn.sharedcache.nested-level</td><td>3</td></tr><tr><td>yarn.sharedcache.nm.uploader.replication.factor</td><td>10</td></tr><tr><td>yarn.sharedcache.nm.uploader.thread-count</td><td>20</td></tr><tr><td>yarn.sharedcache.root-dir</td><td>/sharedcache</td></tr><tr><td>yarn.sharedcache.store.class</td><td>org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore</td></tr><tr><td>yarn.sharedcache.store.in-memory.check-period-mins</td><td>720</td></tr><tr><td>yarn.sharedcache.store.in-memory.initial-delay-mins</td><td>10</td></tr><tr><td>yarn.sharedcache.store.in-memory.staleness-period-mins</td><td>10080</td></tr><tr><td>yarn.sharedcache.uploader.server.address</td><td>0.0.0.0:8046</td></tr><tr><td>yarn.sharedcache.uploader.server.thread-count</td><td>50</td></tr><tr><td>yarn.sharedcache.webapp.address</td><td>0.0.0.0:8788</td></tr><tr><td>yarn.timeline-service.address</td><td>${yarn.timeline-service.hostname}:10200</td></tr><tr><td>yarn.timeline-service.client.best-effort</td><td>false</td></tr><tr><td>yarn.timeline-service.client.max-retries</td><td>30</td></tr><tr><td>yarn.timeline-service.client.retry-interval-ms</td><td>1000</td></tr><tr><td>yarn.timeline-service.enabled</td><td>false</td></tr><tr><td>yarn.timeline-service.generic-application-history.max-applications</td><td>10000</td></tr><tr><td>yarn.timeline-service.handler-thread-count</td><td>10</td></tr><tr><td>yarn.timeline-service.hostname</td><td>0.0.0.0</td></tr><tr><td>yarn.timeline-service.http-authentication.simple.anonymous.allowed</td><td>true</td></tr><tr><td>yarn.timeline-service.http-authentication.type</td><td>simple</td></tr><tr><td>yarn.timeline-service.keytab</td><td>/etc/krb5.keytab</td></tr><tr><td>yarn.timeline-service.leveldb-state-store.path</td><td>${hadoop.tmp.dir}/yarn/timeline</td></tr><tr><td>yarn.timeline-service.leveldb-timeline-store.path</td><td>${hadoop.tmp.dir}/yarn/timeline</td></tr><tr><td>yarn.timeline-service.leveldb-timeline-store.read-cache-size</td><td>104857600</td></tr><tr><td>yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size</td><td>10000</td></tr><tr><td>yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size</td><td>10000</td></tr><tr><td>yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms</td><td>300000</td></tr><tr><td>yarn.timeline-service.recovery.enabled</td><td>false</td></tr><tr><td>yarn.timeline-service.state-store-class</td><td>org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore</td></tr><tr><td>yarn.timeline-service.store-class</td><td>org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore</td></tr><tr><td>yarn.timeline-service.ttl-enable</td><td>true</td></tr><tr><td>yarn.timeline-service.ttl-ms</td><td>604800000</td></tr><tr><td>yarn.timeline-service.webapp.address</td><td>${yarn.timeline-service.hostname}:8188</td></tr><tr><td>yarn.timeline-service.webapp.https.address</td><td>${yarn.timeline-service.hostname}:8190</td></tr>
      </tbody>
    <tfoot></tfoot></table>
        </div>
        <span class="collapse-aggregated-systemProperties collapse-table" onclick="collapseTable('collapse-aggregated-systemProperties',
            'aggregated-systemProperties')">
          <h4>
            <span class="collapse-table-arrow arrow-open"></span>
            <a>System Properties</a>
          </h4>
        </span>
        <div class="aggregated-systemProperties collapsible-table">
          <table class="table table-bordered table-condensed table-striped sortable">
      <thead><tr><th class="sorttable_alpha" width="50.0%">Name</th><th class="sorttable_alpha" width="50.0%">Value</th></tr></thead>
      <tbody>
        <tr><td>SPARK_SUBMIT</td><td>true</td></tr><tr><td>awt.toolkit</td><td>sun.awt.X11.XToolkit</td></tr><tr><td>file.encoding</td><td>UTF-8</td></tr><tr><td>file.encoding.pkg</td><td>sun.io</td></tr><tr><td>file.separator</td><td>/</td></tr><tr><td>java.awt.graphicsenv</td><td>sun.awt.X11GraphicsEnvironment</td></tr><tr><td>java.awt.printerjob</td><td>sun.print.PSPrinterJob</td></tr><tr><td>java.class.version</td><td>52.0</td></tr><tr><td>java.endorsed.dirs</td><td>/usr/local/openjdk-8/jre/lib/endorsed</td></tr><tr><td>java.ext.dirs</td><td>/usr/local/openjdk-8/jre/lib/ext:/usr/java/packages/lib/ext</td></tr><tr><td>java.home</td><td>/usr/local/openjdk-8/jre</td></tr><tr><td>java.io.tmpdir</td><td>/tmp</td></tr><tr><td>java.library.path</td><td>/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib</td></tr><tr><td>java.runtime.name</td><td>OpenJDK Runtime Environment</td></tr><tr><td>java.runtime.version</td><td>1.8.0_212-b04</td></tr><tr><td>java.specification.name</td><td>Java Platform API Specification</td></tr><tr><td>java.specification.vendor</td><td>Oracle Corporation</td></tr><tr><td>java.specification.version</td><td>1.8</td></tr><tr><td>java.vendor</td><td>Oracle Corporation</td></tr><tr><td>java.vendor.url</td><td>http://java.oracle.com/</td></tr><tr><td>java.vendor.url.bug</td><td>http://bugreport.sun.com/bugreport/</td></tr><tr><td>java.version</td><td>1.8.0_212</td></tr><tr><td>java.vm.info</td><td>mixed mode</td></tr><tr><td>java.vm.name</td><td>OpenJDK 64-Bit Server VM</td></tr><tr><td>java.vm.specification.name</td><td>Java Virtual Machine Specification</td></tr><tr><td>java.vm.specification.vendor</td><td>Oracle Corporation</td></tr><tr><td>java.vm.specification.version</td><td>1.8</td></tr><tr><td>java.vm.vendor</td><td>Oracle Corporation</td></tr><tr><td>java.vm.version</td><td>25.212-b04</td></tr><tr><td>jetty.git.hash</td><td>e1bc35120a6617ee3df052294e433f3a25ce7097</td></tr><tr><td>line.separator</td><td>
</td></tr><tr><td>os.arch</td><td>amd64</td></tr><tr><td>os.name</td><td>Linux</td></tr><tr><td>os.version</td><td>4.19.121-linuxkit</td></tr><tr><td>path.separator</td><td>:</td></tr><tr><td>scala.usejavacp</td><td>true</td></tr><tr><td>sun.arch.data.model</td><td>64</td></tr><tr><td>sun.boot.class.path</td><td>/usr/local/openjdk-8/jre/lib/resources.jar:/usr/local/openjdk-8/jre/lib/rt.jar:/usr/local/openjdk-8/jre/lib/sunrsasign.jar:/usr/local/openjdk-8/jre/lib/jsse.jar:/usr/local/openjdk-8/jre/lib/jce.jar:/usr/local/openjdk-8/jre/lib/charsets.jar:/usr/local/openjdk-8/jre/lib/jfr.jar:/usr/local/openjdk-8/jre/classes</td></tr><tr><td>sun.boot.library.path</td><td>/usr/local/openjdk-8/jre/lib/amd64</td></tr><tr><td>sun.cpu.endian</td><td>little</td></tr><tr><td>sun.cpu.isalist</td><td></td></tr><tr><td>sun.io.unicode.encoding</td><td>UnicodeLittle</td></tr><tr><td>sun.java.command</td><td>org.apache.spark.deploy.SparkSubmit --class org.apache.spark.repl.Main --name Spark shell spark-shell</td></tr><tr><td>sun.java.launcher</td><td>SUN_STANDARD</td></tr><tr><td>sun.jnu.encoding</td><td>UTF-8</td></tr><tr><td>sun.management.compiler</td><td>HotSpot 64-Bit Tiered Compilers</td></tr><tr><td>sun.nio.ch.bugLevel</td><td></td></tr><tr><td>sun.os.patch.level</td><td>unknown</td></tr><tr><td>user.dir</td><td>/spark/bin</td></tr><tr><td>user.home</td><td>/root</td></tr><tr><td>user.language</td><td>en</td></tr><tr><td>user.name</td><td>root</td></tr><tr><td>user.timezone</td><td>Etc/UTC</td></tr>
      </tbody>
    <tfoot></tfoot></table>
        </div>
        <span class="collapse-aggregated-classpathEntries collapse-table" onclick="collapseTable('collapse-aggregated-classpathEntries',
            'aggregated-classpathEntries')">
          <h4>
            <span class="collapse-table-arrow arrow-open"></span>
            <a>Classpath Entries</a>
          </h4>
        </span>
        <div class="aggregated-classpathEntries collapsible-table">
          <table class="table table-bordered table-condensed table-striped sortable">
      <thead><tr><th class="sorttable_alpha" width="50.0%">Resource</th><th class="sorttable_alpha" width="50.0%">Source</th></tr></thead>
      <tbody>
        <tr><td>/spark/conf/</td><td>System Classpath</td></tr><tr><td>/spark/jars/HikariCP-2.5.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/JLargeArrays-1.5.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/JTransforms-3.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/RoaringBitmap-0.7.45.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/ST4-4.0.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/activation-1.1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/aircompressor-0.10.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/algebra_2.12-2.0.0-M2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/antlr-runtime-3.5.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/antlr4-runtime-4.7.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/aopalliance-1.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/aopalliance-repackaged-2.6.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/apacheds-i18n-2.0.0-M15.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/apacheds-kerberos-codec-2.0.0-M15.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/api-asn1-api-1.0.0-M20.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/api-util-1.0.0-M20.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/arpack_combined_all-0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/arrow-format-0.15.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/arrow-memory-0.15.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/arrow-vector-0.15.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/audience-annotations-0.5.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/automaton-1.11-8.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/avro-1.8.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/avro-ipc-1.8.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/avro-mapred-1.8.2-hadoop2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/bonecp-0.8.0.RELEASE.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/breeze-macros_2.12-1.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/breeze_2.12-1.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/cats-kernel_2.12-2.0.0-M4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/chill-java-0.9.5.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/chill_2.12-0.9.5.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-beanutils-1.9.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-cli-1.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-codec-1.10.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-collections-3.2.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-compiler-3.0.16.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-compress-1.8.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-configuration-1.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-crypto-1.0.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-dbcp-1.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-digester-1.8.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-httpclient-3.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-io-2.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-lang-2.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-lang3-3.9.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-logging-1.1.3.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-math3-3.4.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-net-3.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-pool-1.5.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/commons-text-1.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/compress-lzf-1.0.3.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/core-1.1.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/curator-client-2.7.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/curator-framework-2.7.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/curator-recipes-2.7.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/datanucleus-api-jdo-4.2.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/datanucleus-core-4.1.17.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/datanucleus-rdbms-4.1.19.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/derby-10.12.1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/flatbuffers-java-1.9.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/generex-1.0.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/gson-2.2.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/guava-14.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/guice-3.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/guice-servlet-3.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-annotations-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-auth-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-client-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-common-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-hdfs-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-mapreduce-client-app-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-mapreduce-client-common-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-mapreduce-client-core-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-mapreduce-client-jobclient-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-mapreduce-client-shuffle-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-yarn-api-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-yarn-client-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-yarn-common-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-yarn-server-common-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hadoop-yarn-server-web-proxy-2.7.4.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-beeline-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-cli-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-common-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-exec-2.3.7-core.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-jdbc-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-llap-common-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-metastore-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-serde-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-shims-0.23-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-shims-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-shims-common-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-shims-scheduler-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-storage-api-2.7.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hive-vector-code-gen-2.3.7.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hk2-api-2.6.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hk2-locator-2.6.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/hk2-utils-2.6.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/htrace-core-3.1.0-incubating.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/httpclient-4.5.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/httpcore-4.4.12.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/istack-commons-runtime-3.0.8.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/ivy-2.4.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-annotations-2.10.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-core-2.10.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-core-asl-1.9.13.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-databind-2.10.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-dataformat-yaml-2.10.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-datatype-jsr310-2.10.3.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-jaxrs-1.9.13.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-mapper-asl-1.9.13.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-module-jaxb-annotations-2.10.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-module-paranamer-2.10.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-module-scala_2.12-2.10.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jackson-xc-1.9.13.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jakarta.activation-api-1.2.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jakarta.annotation-api-1.3.5.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jakarta.inject-2.6.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jakarta.validation-api-2.0.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jakarta.ws.rs-api-2.1.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jakarta.xml.bind-api-2.3.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/janino-3.0.16.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/javassist-3.25.0-GA.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/javax.inject-1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/javax.jdo-3.2.0-m3.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/javax.servlet-api-3.1.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/javolution-5.5.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jaxb-api-2.2.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jaxb-runtime-2.3.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jcl-over-slf4j-1.7.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jdo-api-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jersey-client-2.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jersey-common-2.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jersey-container-servlet-2.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jersey-container-servlet-core-2.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jersey-hk2-2.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jersey-media-jaxb-2.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jersey-server-2.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jetty-6.1.26.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jetty-sslengine-6.1.26.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jetty-util-6.1.26.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jline-2.14.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/joda-time-2.10.5.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jodd-core-3.5.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jpam-1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/json-1.8.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/json4s-ast_2.12-3.6.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/json4s-core_2.12-3.6.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/json4s-jackson_2.12-3.6.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/json4s-scalap_2.12-3.6.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jsp-api-2.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jsr305-3.0.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jta-1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/jul-to-slf4j-1.7.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/kryo-shaded-4.0.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/kubernetes-client-4.9.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/kubernetes-model-4.9.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/kubernetes-model-common-4.9.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/leveldbjni-all-1.8.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/libfb303-0.9.3.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/libthrift-0.12.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/log4j-1.2.17.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/logging-interceptor-3.12.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/lz4-java-1.7.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/machinist_2.12-0.6.8.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/macro-compat_2.12-1.1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/mesos-1.4.0-shaded-protobuf.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/metrics-core-4.1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/metrics-graphite-4.1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/metrics-jmx-4.1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/metrics-json-4.1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/metrics-jvm-4.1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/minlog-1.3.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/netty-all-4.1.47.Final.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/objenesis-2.5.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/okhttp-3.12.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/okio-1.15.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/opencsv-2.3.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/orc-core-1.5.10.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/orc-mapreduce-1.5.10.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/orc-shims-1.5.10.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/oro-2.0.8.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/osgi-resource-locator-1.0.3.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/paranamer-2.8.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/parquet-column-1.10.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/parquet-common-1.10.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/parquet-encoding-1.10.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/parquet-format-2.4.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/parquet-hadoop-1.10.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/parquet-jackson-1.10.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/protobuf-java-2.5.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/py4j-0.10.9.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/pyrolite-4.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/scala-collection-compat_2.12-2.1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/scala-compiler-2.12.10.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/scala-library-2.12.10.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/scala-parser-combinators_2.12-1.1.2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/scala-reflect-2.12.10.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/scala-xml_2.12-1.2.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/shapeless_2.12-2.3.3.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/shims-0.7.45.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/slf4j-api-1.7.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/slf4j-log4j12-1.7.30.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/snakeyaml-1.24.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/snappy-java-1.1.7.5.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-catalyst_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-core_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-graphx_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-hive-thriftserver_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-hive_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-kubernetes_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-kvstore_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-launcher_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-mesos_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-mllib-local_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-mllib_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-network-common_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-network-shuffle_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-repl_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-sketch_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-sql_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-streaming_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-tags_2.12-3.0.1-tests.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-tags_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-unsafe_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spark-yarn_2.12-3.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spire-macros_2.12-0.17.0-M1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spire-platform_2.12-0.17.0-M1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spire-util_2.12-0.17.0-M1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/spire_2.12-0.17.0-M1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/stax-api-1.0-2.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/stax-api-1.0.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/stream-2.9.6.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/super-csv-2.2.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/threeten-extra-1.5.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/transaction-api-1.1.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/univocity-parsers-2.9.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/velocity-1.5.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/xbean-asm7-shaded-4.15.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/xercesImpl-2.12.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/xml-apis-1.4.01.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/xmlenc-0.52.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/xz-1.5.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/zjsonpatch-0.3.0.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/zookeeper-3.4.14.jar</td><td>System Classpath</td></tr><tr><td>/spark/jars/zstd-jni-1.4.4-3.jar</td><td>System Classpath</td></tr>
      </tbody>
    <tfoot></tfoot></table>
        </div>
      </span>
        </div>
      
    </body></html>